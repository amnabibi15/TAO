{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "from matplotlib import pyplot as plt, rcParams\n",
    "# import cv2\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"white\", context=\"paper\")\n",
    "from cycler import cycler\n",
    "import os, sys\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import combinations\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO as _BytesIO\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from sklearn.metrics import *\n",
    "import collections\n",
    "from copy import deepcopy\n",
    "pd.options.display.max_columns = None\n",
    "def printm(s): return display(Markdown(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Configs for data fetch and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "overall_cache_dir = \"../../cache/sep12_inc/\"\n",
    "# Result summary prefix\n",
    "result_summary_prefix = 'results_summary'\n",
    "\n",
    "#timestamped predictions prefix\n",
    "ts_prediction_file_prefix = 'timestamped_predictions'\n",
    "\n",
    "# Ground Truth\n",
    "gt_dir = f'../../GT_marking/labelstudio_gt/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## config for various kinds of graphs\n",
    "\n",
    "gconfigs = {\n",
    "    'barplot': {'color': 'blue', 'linestyle': '-.', 'marker': '.', 'alpha': 0.5}\n",
    "}\n",
    "\n",
    "\n",
    "#Percentile calculations\n",
    "def perc_75(x): return np.percentile(x, 75)\n",
    "\n",
    "\n",
    "def perc_25(x): return np.percentile(x, 25)\n",
    "\n",
    "\n",
    "#Set default RC parameters\n",
    "notebook_default_rcparams = {\n",
    "    \"axes.titlesize\": 32,\n",
    "    \"axes.labelsize\": 32,\n",
    "    \"legend.fontsize\": 32,\n",
    "    \"legend.title_fontsize\": 32,\n",
    "    \"xtick.labelsize\": 32,\n",
    "    \"ytick.labelsize\": 32,\n",
    "    \"axes.grid\": True,\n",
    "    \"legend.framealpha\": 0.5,\n",
    "    \"lines.linewidth\": 5,\n",
    "    \"legend.loc\": 'upper left'\n",
    "\n",
    "}\n",
    "rcParams.update(notebook_default_rcparams)\n",
    "\n",
    "# Standardized Labels\n",
    "\n",
    "EPSILON = 2e-2\n",
    "#plotting dir\n",
    "\n",
    "\n",
    "plotting_dir = f'plots/{datetime.now().strftime(\"%Y%m%d\")}'\n",
    "if not os.path.exists(plotting_dir):\n",
    "    os.makedirs(plotting_dir)\n",
    "out_result_dir = f'results/{datetime.now().strftime(\"%Y%m%d\")}'\n",
    "if not os.path.exists(out_result_dir):\n",
    "    os.makedirs(out_result_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Ground truth collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>task_url</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>context</th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00EABED2-271D-49D8-B599-1D4A09240601</td>\n",
       "      <td>a21f9208-2015-10-07</td>\n",
       "      <td>1.444252e+09</td>\n",
       "      <td>1.444252e+09</td>\n",
       "      <td>Commuting</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00EABED2-271D-49D8-B599-1D4A09240601</td>\n",
       "      <td>a21f9208-2015-10-07</td>\n",
       "      <td>1.444233e+09</td>\n",
       "      <td>1.444234e+09</td>\n",
       "      <td>Commuting</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00EABED2-271D-49D8-B599-1D4A09240601</td>\n",
       "      <td>a21f9208-2015-10-07</td>\n",
       "      <td>1.444249e+09</td>\n",
       "      <td>1.444249e+09</td>\n",
       "      <td>InAMeeting</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00EABED2-271D-49D8-B599-1D4A09240601</td>\n",
       "      <td>07ac640a-2015-10-08</td>\n",
       "      <td>1.444348e+09</td>\n",
       "      <td>1.444374e+09</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>25651.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00EABED2-271D-49D8-B599-1D4A09240601</td>\n",
       "      <td>07ac640a-2015-10-08</td>\n",
       "      <td>1.444341e+09</td>\n",
       "      <td>1.444341e+09</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id             task_url    start_time  \\\n",
       "0  00EABED2-271D-49D8-B599-1D4A09240601  a21f9208-2015-10-07  1.444252e+09   \n",
       "1  00EABED2-271D-49D8-B599-1D4A09240601  a21f9208-2015-10-07  1.444233e+09   \n",
       "2  00EABED2-271D-49D8-B599-1D4A09240601  a21f9208-2015-10-07  1.444249e+09   \n",
       "3  00EABED2-271D-49D8-B599-1D4A09240601  07ac640a-2015-10-08  1.444348e+09   \n",
       "4  00EABED2-271D-49D8-B599-1D4A09240601  07ac640a-2015-10-08  1.444341e+09   \n",
       "\n",
       "       end_time     context  total_time  \n",
       "0  1.444252e+09   Commuting         1.0  \n",
       "1  1.444234e+09   Commuting       480.0  \n",
       "2  1.444249e+09  InAMeeting         1.0  \n",
       "3  1.444374e+09    Sleeping     25651.0  \n",
       "4  1.444341e+09    Sleeping         1.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_dict = {}\n",
    "if True:\n",
    "    df_gt = None\n",
    "    gt_ids = glob.glob(f\"{gt_dir}/*.json\")\n",
    "    list_gt_raw=[]\n",
    "    for id_file in gt_ids:\n",
    "        # print(f\"collecting labels for id file {id_file}\")\n",
    "        id_gt_dict = json.load(open(id_file,'r'))\n",
    "        id = id_file.split(\"/\")[-1].split(\".json\")[0]\n",
    "        for task_idx in range(len(id_gt_dict)):\n",
    "            task_url = id_gt_dict[task_idx]['timeseriesUrl'].split(\"/\")[-1].split(\".\")[0]\n",
    "            label_info = id_gt_dict[task_idx]['label']\n",
    "            for label_dict in label_info:\n",
    "                label_start,label_end = label_dict['start'], label_dict['end']\n",
    "                # print(\"Before conversion\",task_url,label_start,label_end)\n",
    "                try:\n",
    "                    label_start = pd.to_datetime(label_start,format=\"%Y-%m-%d %H:%M:%S\" )\n",
    "                    label_end = pd.to_datetime(label_end,format=\"%Y-%m-%d %H:%M:%S\" )\n",
    "                    if label_dict['instant']:\n",
    "                        label_end = label_end + timedelta(seconds=1)\n",
    "                    if not (id[:3]=='csh'): #it's and extrasensory id\n",
    "                        label_start = label_start.tz_localize('America/Los_Angeles')\n",
    "                        label_end = label_end.tz_localize('America/Los_Angeles')\n",
    "                    label_start_timestamp = label_start.timestamp()\n",
    "                    label_end_timestamp = label_end.timestamp()\n",
    "                    label_value = \",\".join(label_dict['timeserieslabels'])\n",
    "                    list_gt_raw.append([id,task_url,label_start_timestamp,label_end_timestamp,label_value])\n",
    "                except:\n",
    "                    # print(label_dict)\n",
    "                    ...\n",
    "    df_gt = pd.DataFrame(np.array(list_gt_raw),columns=['id','task_url','start_time','end_time','context'])\n",
    "    df_gt['start_time'] = df_gt['start_time'].astype(float)\n",
    "    df_gt['end_time'] = df_gt['end_time'].astype(float)\n",
    "    df_gt['context'] = df_gt['context'].apply(lambda x: 'Amusement' if (x=='1') else x)\n",
    "    df_gt['context'] = df_gt['context'].apply(lambda x: 'Commuting' if (x=='2') else x)\n",
    "    df_gt['context'] = df_gt['context'].apply(lambda x: 'Exercising' if (x=='3') else x)\n",
    "    df_gt['context'] = df_gt['context'].apply(lambda x: 'GoingOut' if (x=='4') else x)\n",
    "    df_gt['context'] = df_gt['context'].apply(lambda x: 'HavingMeal' if (x=='a') else x)\n",
    "    gt_dict['instance_counts'] = df_gt['context'].value_counts()\n",
    "    df_gt.id.drop_duplicates().values.tolist()\n",
    "    df_gt['total_time'] = df_gt['end_time'].astype(float) - df_gt['start_time'].astype(float)\n",
    "    gt_dict['total_times'] = df_gt.groupby('context')['total_time'].sum() / 3600.\n",
    "    # df_gt[df_gt.id.isin(['csh101','csh102'])].groupby('context')['total_time'].sum().sort_index() / 3600.\n",
    "# df_gt.info()\n",
    "df_gt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Ontology, Ontological predictions and Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " # Onotlogy Graphs and Labeling contexts with ontology\n",
    "if True:\n",
    "\n",
    "    df_onto = pd.read_csv('../../ontological_models/ontology_labels_aug11.csv', names=['activities', 'contexts'])\n",
    "    df_onto['contexts'] = df_onto['contexts'].apply(lambda x: x.split(\";\"))\n",
    "    onto_dict = df_onto.set_index('activities').to_dict()['contexts']\n",
    "\n",
    "    df_onto_pred = pd.read_csv('../../ontological_models/ontology_predictions_v2.csv')\n",
    "    df_onto_pred['tao_prediction'] = df_onto_pred['tao_prediction'].apply(lambda x: x.split(\";\") if not (str(x)=='nan') else ['Unknown'])\n",
    "    # df_onto_pred = pd.read_csv('../../cache/df_gt_with_activities_aug12.csv')\n",
    "    # df_onto_pred['tao_prediction'] = df_onto_pred['gt_context'].apply(lambda x: x.split(\",\") if not (str(x)=='nan') else ['Unknown'])\n",
    "\n",
    "\n",
    "    activity_rename_mapping = {\n",
    "        'extrasensory': {\n",
    "        'lying': 'LyingDown',\n",
    "        'sitting': 'Sitting',\n",
    "        'walking': 'Walking',\n",
    "        'running': 'Running',\n",
    "        'cycling': 'Cycling',\n",
    "        'sleeping': 'Sleeping',\n",
    "        'meeting': 'Meeting',\n",
    "        'driving': 'Driving',\n",
    "        'exercising': 'Hiking',\n",
    "        'cooking': 'Cooking',\n",
    "        'shopping': 'Shopping',\n",
    "        'drinking': 'Drinking',\n",
    "        'shower': 'Shower',\n",
    "        'cleaning': 'VacuumHome',\n",
    "        'laundry': 'VacuumHome',\n",
    "        'clean_dishes': 'VacuumHome',\n",
    "        'watching_tv': 'WatchingTv',\n",
    "        'surfing_internet': 'ReadingOffice',\n",
    "        'singing': 'Dancing',\n",
    "        'talking': 'Talking',\n",
    "        'office_work': 'TypingOffice',\n",
    "        'eating': 'Eating',\n",
    "        'toilet': 'Toilet',\n",
    "        'grooming': 'Grooming',\n",
    "        'dressing_up': 'Grooming',\n",
    "        'stairs': 'ClimbingStairs',\n",
    "        'standing': 'Standing',\n",
    "        'meeting_coworkers': 'Meeting',\n",
    "        'meeting_friends': 'Dancing',\n",
    "\n",
    "    },\n",
    "        'casas': {\n",
    "            'step_out': 'StepOut',\n",
    "            'none': 'None',\n",
    "            'toilet': 'Toilet',\n",
    "            'onphone': 'OnPhone',\n",
    "            'grooming': 'Grooming',\n",
    "            'step_in': 'StepIn',\n",
    "            'lying': 'LyingDown',\n",
    "            'drinking': 'Drinking',\n",
    "            'watching_tv': 'WatchingTv',\n",
    "            'dressing_up': 'Grooming',\n",
    "            'taking_meds': 'Eating',\n",
    "            'wakingup': 'Sleeping',\n",
    "            'reading': 'TypingOffice',\n",
    "            'cooking': 'Cooking',\n",
    "            'eating': 'Eating',\n",
    "            'shower': 'Shower',\n",
    "            'sleeping': 'Sleeping',\n",
    "            'office_work': 'SittingOffice',\n",
    "            'dishes_home': 'VacuumHome',\n",
    "            'meeting_friends': 'Dancing',\n",
    "            'exercising': 'Running',\n",
    "            'laundry_home': 'VacuumHome'\n",
    "        },\n",
    "        'tsu': {\n",
    "            \"boil_water\": \"Cooking\",\n",
    "            \"clean_with_water\": \"VacuumHome\",\n",
    "            \"cut_cook\": \"Cooking\",\n",
    "            \"cut_bread\": \"Cooking\",\n",
    "            \"drink_cold\": \"Drinking\",\n",
    "            \"drink_hot\": \"Drinking\",\n",
    "            \"dry_up\": \"VacuumHome\",\n",
    "            \"dump_in_trash\": \"VacuumHome\",\n",
    "            \"eat_food\": \"Eating\",\n",
    "            \"eat_snack\": \"Eating\",\n",
    "            \"enter\": \"StepIn\",\n",
    "            \"get_up\": \"Sleeping\",\n",
    "            \"get_water\": \"Eating\",\n",
    "            \"insert_tea_bag\": \"Drinking\",\n",
    "            \"lay_down\": \"LyingDown\",\n",
    "            \"leave\": \"StepOut\",\n",
    "            \"pour_grains\": \"Drinking\",\n",
    "            \"pour_water\": \"Drinking\",\n",
    "            \"pour_cold\": \"Drinking\",\n",
    "            \"pour_hot\": \"Drinking\",\n",
    "            \"put_in_sink\": \"VacuumHome\",\n",
    "            \"put_on_table\": \"VacuumHome\",\n",
    "            \"read\": \"ReadingOffice\",\n",
    "            \"sit_down\": \"Sitting\",\n",
    "            \"spread_jam_or_butter\": \"Eating\",\n",
    "            \"stir_cook\": \"Cooking\",\n",
    "            \"stir_drink\": \"Drinking\",\n",
    "            \"take_ham\": \"Cooking\",\n",
    "            \"take_meds\": \"Eating\",\n",
    "            \"take_off_table\": \"Eating\",\n",
    "            \"use_furniture\": \"VacuumHome\",\n",
    "            \"use_glasses\": \"Eating\",\n",
    "            \"use_pc\": \"TypingOffice\",\n",
    "            \"use_kitchen_utility\": \"VacuumHome\",\n",
    "            \"use_telephone\": \"onPhone\",\n",
    "            \"walk\": \"Walking\",\n",
    "            \"watch_tv\": \"WatchingTv\",\n",
    "            \"clean_table\": \"VacuumHome\",\n",
    "            \"write\": \"ReadingOffice\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    tsu_context_mapping = {\n",
    "        \"ComingIn\": [\"tsuBreakfast\"],\n",
    "        \"Commuting\": [\"tsuBreakfast\", \"tsuCook\"],\n",
    "        \"GoingOut\": [\"tsuBreakfast\"],\n",
    "        \"HavingMeal\": [\"tsuMakecoffee\", \"tsuMaketea\"],\n",
    "        \"HouseWork\": [\"tsuCleandishes\"],\n",
    "        \"PreparingMeal\": [\"tsuCook\"],\n",
    "        \"Relaxing\": [\"tsuBreakfast\"],\n",
    "    }\n",
    "\n",
    "def label_context_v1(cluster_representation, activity_renaming,conf_activities=['sitting','standing','talking']):\n",
    "    # print(cluster_representation)\n",
    "    act_train = cluster_representation.split(\">\")\n",
    "    act_train = [xr.split(\"+\") for xr in act_train]\n",
    "\n",
    "    unique_activities = set()\n",
    "    for act_set in act_train:\n",
    "        for activity in act_set:\n",
    "            unique_activities.add(activity)\n",
    "    for conf_act in conf_activities:\n",
    "        try:\n",
    "            unique_activities.remove(conf_act)\n",
    "        except:\n",
    "            ...\n",
    "\n",
    "\n",
    "    if len(unique_activities)>0:\n",
    "        # print(\"More than conf activities in the set, removing conf activities for precise context labeling\")\n",
    "        act_train = [([activity for activity in act_set if (activity not in conf_activities)]) for act_set in act_train]\n",
    "        # print(act_train)\n",
    "\n",
    "\n",
    "    for i in range(len(act_train)):\n",
    "        for j in range(len(act_train[i])):\n",
    "            # print(act_train,act_train[i], act_train[i][j])\n",
    "            if not act_train[i][j]=='unknown':\n",
    "                act_train[i][j] = activity_renaming[act_train[i][j]].lower()\n",
    "            else:\n",
    "                act_train[i][j] = 'none'\n",
    "        act_train[i] = sorted(np.unique(act_train[i]).tolist())\n",
    "\n",
    "    #for sequential contexts\n",
    "    # try:\n",
    "    seq_contexts = []\n",
    "    for i in range(1, len(act_train)):\n",
    "        set1, set2 = act_train[i - 1], act_train[i]\n",
    "        for first_act in set1:\n",
    "            for sec_act in set2:\n",
    "                # print(f\"seq: {first_act},{sec_act}\")\n",
    "                if not first_act == sec_act:\n",
    "                    try:\n",
    "                        seq_ctx = onto_dict[\n",
    "                            f'{first_act}+{sec_act}']\n",
    "                        if not (seq_ctx[0] == 'Unknown'):\n",
    "                            seq_contexts += seq_ctx\n",
    "                    except:\n",
    "                        ...\n",
    "\n",
    "    # for parallel contexts\n",
    "    single_act_contexts = []\n",
    "    par_contexts = []\n",
    "    for act_set in act_train:\n",
    "        if len(act_set) == 1:\n",
    "            single_ctx = onto_dict[f\"{act_set[0]}\"]\n",
    "            if not (single_ctx[0] == 'Unknown'):\n",
    "                single_act_contexts += single_ctx\n",
    "        else:\n",
    "            for act1, act2 in combinations(act_set, 2):\n",
    "                if not act1 == act2:\n",
    "                    par_ctx = ['Unknown']\n",
    "                    try:\n",
    "                        par_ctx = onto_dict[f\"{act1}_{act2}\"]\n",
    "                    except:\n",
    "                        par_ctx = onto_dict[f\"{act2}_{act1}\"]\n",
    "                    if not (par_ctx[0] == 'Unknown'):\n",
    "                        par_contexts += par_ctx\n",
    "\n",
    "    final_context_set = None\n",
    "    if len(seq_contexts) > 0:\n",
    "        final_context_set = np.unique(seq_contexts).tolist()\n",
    "    elif len(par_contexts) > 0:\n",
    "        final_context_set = np.unique(par_contexts).tolist()\n",
    "    elif len(single_act_contexts) > 0:\n",
    "        final_context_set = np.unique(single_act_contexts).tolist()\n",
    "    else:\n",
    "        all_contexts = []\n",
    "        for act_set in act_train:\n",
    "            for activity in act_set:\n",
    "                single_ctx = onto_dict[f\"{activity}\"]\n",
    "                if not (single_ctx[0] == 'Unknown'):\n",
    "                    all_contexts += single_ctx\n",
    "        final_context_set = np.unique(all_contexts).tolist()\n",
    "\n",
    "    # tsu specific conversion\n",
    "    if dataset == 'tsu':\n",
    "        tsu_final_contexts = []\n",
    "        for context in final_context_set:\n",
    "            if context in tsu_context_mapping.keys():\n",
    "                tsu_final_contexts += tsu_context_mapping[context]\n",
    "        if len(tsu_final_contexts) > 0:\n",
    "            return np.unique(tsu_final_contexts).tolist()\n",
    "        else:\n",
    "            return ['Unknown']\n",
    "    else:\n",
    "        return final_context_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def get_ctx_vec(ctx_str, contexts):\n",
    "    ctx_vec = np.zeros(len(contexts))\n",
    "    for item_i in ctx_str.split(\",\"):\n",
    "        if not item_i in ['','Unknown']:\n",
    "            ctx_vec[contexts.index(item_i)] = 1\n",
    "    return ctx_vec\n",
    "\n",
    "def get_cluster_labels(cluster_centers, dataset, labeling_func=label_context_v1):\n",
    "    cluster_centers = [center.split(\")__\")[0].split(\"(\")[-1] for center in cluster_centers]\n",
    "    cluster_labels = [labeling_func(center, activity_rename_mapping[dataset]) for center in cluster_centers]\n",
    "    return cluster_labels\n",
    "\n",
    "def compile_ts_results_v2(ts_results, df_onto_pred, df_gt, cluster_labels):\n",
    "    #compiled final timestamped results with GT\n",
    "    compiled_ts_results_dict = dict()\n",
    "    # compiled_instance_results_dict = dict()\n",
    "    for key in ts_results.keys():\n",
    "        df_pred_id = ts_results[key]\n",
    "        df_pred_id['id'] = key\n",
    "        df_gt_id = df_gt[df_gt.id == key]\n",
    "        df_onto_pred_id = df_onto_pred[df_onto_pred.id==key]\n",
    "        df_pred_id = df_pred_id[df_pred_id.end_timestamp >= df_gt_id.start_time.min()]\n",
    "        df_pred_id = df_pred_id[df_pred_id.start_timestamp <= df_gt_id.end_time.max()]\n",
    "        if (df_gt_id.shape[0] > 0) & (df_pred_id.shape[0] > 0) & (df_onto_pred_id.shape[0] > 0):\n",
    "            # if (df_gt_id.shape[0] > 0) & (df_pred_id.shape[0] > 0):\n",
    "            print(f\"Starting on {key}\")\n",
    "            #process gt to timestamp, context format\n",
    "            gt_min_ts, gt_max_ts = df_gt_id.start_time.min(), df_gt_id.end_time.max()\n",
    "            df_gt_ts = pd.DataFrame(np.arange(gt_min_ts, gt_max_ts + 1), columns=['timestamp'])\n",
    "            df_gt_ts['gt_context'] = ''\n",
    "            df_gt_ts = df_gt_ts.set_index('timestamp')\n",
    "            for row_idx, row in df_gt_id.iterrows():\n",
    "                df_gt_ts.loc[row['start_time']:row['end_time'], 'gt_context'] = df_gt_ts.loc[\n",
    "                                                                                row['start_time']:row['end_time'],\n",
    "                                                                                'gt_context'].apply(\n",
    "                    lambda x: row['context'] if (x == '') else (x + ',' + row['context']))\n",
    "\n",
    "            #get ts based prediction\n",
    "            pred_min_ts, pred_max_ts = df_pred_id.start_timestamp.min(), df_pred_id.end_timestamp.max()\n",
    "            df_pred_ts = pd.DataFrame(np.arange(pred_min_ts, pred_max_ts + 1), columns=['timestamp'])\n",
    "            df_pred_ts['pred_context'] = None\n",
    "            df_pred_ts = df_pred_ts.set_index('timestamp')\n",
    "            for row_idx, row in df_pred_id.iterrows():\n",
    "                df_pred_ts.loc[row['start_timestamp']:row['end_timestamp'], 'pred_context'] = df_pred_ts.loc[\n",
    "                                                                                              row['start_timestamp']:\n",
    "                                                                                              row['end_timestamp'],\n",
    "                                                                                              'pred_context'].apply(\n",
    "                    lambda x: (x + cluster_labels[row['cluster_id']]) if x is not None else cluster_labels[\n",
    "                        row['cluster_id']])\n",
    "\n",
    "\n",
    "            #merge timestaped gt and predictions together for the user\n",
    "            df_compiled_results_ts_id = pd.merge(df_pred_ts.reset_index(), df_gt_ts.reset_index(), on='timestamp')\n",
    "            df_compiled_results_ts_id['id'] = key\n",
    "            df_compiled_results_ts_id = df_compiled_results_ts_id[\n",
    "                ['id', 'timestamp', 'gt_context', 'pred_context']]\n",
    "            df_compiled_results_ts_id = df_compiled_results_ts_id[~df_compiled_results_ts_id.gt_context.isnull()]\n",
    "            df_compiled_results_ts_id = df_compiled_results_ts_id[~df_compiled_results_ts_id.pred_context.isnull()]\n",
    "            # df_compiled_results_ts_id = pd.merge(df_compiled_results_ts_id,df_onto_pred_id,on =['id','timestamp'],suffixes=('','_onto'))\n",
    "            # df_compiled_results_ts_id['combined_context'] = df_compiled_results_ts_id.apply(lambda row: row['pred_context']+row['tao_prediction'],axis=1)\n",
    "\n",
    "            #added because no results for ontology\n",
    "            df_compiled_results_ts_id = pd.merge(df_compiled_results_ts_id,df_onto_pred_id,on =['id','timestamp'],suffixes=('','_onto'),how='left')\n",
    "            df_compiled_results_ts_id['tao_prediction'] = df_compiled_results_ts_id['tao_prediction'].apply(lambda x: ['Unknown'] if (str(x)=='nan') else x)\n",
    "            df_compiled_results_ts_id['combined_context'] = df_compiled_results_ts_id.apply(lambda row: row['pred_context'],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "            # format as a comma separated string\n",
    "            df_compiled_results_ts_id['onto_context'] = df_compiled_results_ts_id['tao_prediction'].apply(\n",
    "                lambda x: ','.join(sorted(np.unique(x).tolist())))\n",
    "            df_compiled_results_ts_id['pred_context'] = df_compiled_results_ts_id['pred_context'].apply(\n",
    "                lambda x: ','.join(sorted(np.unique(x).tolist())))\n",
    "            df_compiled_results_ts_id['combined_context'] = df_compiled_results_ts_id['combined_context'].apply(\n",
    "                lambda x: ','.join(sorted(np.unique(x).tolist())))\n",
    "\n",
    "            #todo: added to deactivate ontology\n",
    "            # df_compiled_results_ts_id['onto_context'] = df_compiled_results_ts_id['pred_context']\n",
    "            # df_compiled_results_ts_id['combined_context'] = df_compiled_results_ts_id['pred_context']\n",
    "\n",
    "            compiled_ts_results_dict[key] = df_compiled_results_ts_id\n",
    "            print(f\"Processed for id {key}\")\n",
    "    return compiled_ts_results_dict\n",
    "\n",
    "def find_all_present_contexts(df_gt_ts):\n",
    "    '''\n",
    "\n",
    "    :param df_gt_ts:\n",
    "    :type df_gt_ts:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    '''\n",
    "    context_set = set()\n",
    "    for context in df_gt_ts['gt_context'].unique():\n",
    "        for item in context.split(\",\"):\n",
    "            context_set.add(item)\n",
    "\n",
    "    for context in df_gt_ts['pred_context'].unique():\n",
    "        for item in context.split(\",\"):\n",
    "            context_set.add(item)\n",
    "\n",
    "    context_set.remove('')\n",
    "    all_contexts = sorted(list(context_set))\n",
    "    return all_contexts\n",
    "\n",
    "def get_overall_metrics(gt_arr, pred_arr):\n",
    "\n",
    "    # calculate spot by converting it into +0.2 JC\n",
    "    gt_or_pred = np.sum(np.logical_or(gt_arr,pred_arr),axis=1)\n",
    "    gt_eq_pred = np.sum(np.logical_and(gt_arr,pred_arr),axis=1)\n",
    "    jc_samples = gt_eq_pred/gt_or_pred\n",
    "    is_spot = jc_samples>0.2\n",
    "    spot_acc = round(is_spot.sum()*100/is_spot.shape[0],2)\n",
    "    # gt_xor_pred = np.sum(np.logical_xor(gt_arr,pred_arr),axis=1)\n",
    "    # is_norm = (gt_xor_pred==0)\n",
    "    # norm_acc = round(is_norm.sum()*100/is_norm.shape[0],2)\n",
    "\n",
    "\n",
    "\n",
    "    jc_score_samples = round(jaccard_score(gt_arr, pred_arr, average='samples',zero_division=0) * 100, 2)\n",
    "    f1_acc =round(f1_score(gt_arr, pred_arr, average='weighted',zero_division=0) * 100, 2)\n",
    "    avg_prec = round(precision_score(gt_arr, pred_arr, average='weighted',zero_division=0) * 100, 2)\n",
    "    avg_recall = round(recall_score(gt_arr, pred_arr, average='weighted',zero_division=0) * 100, 2)\n",
    "    avg_f1 = round(f1_score(gt_arr, pred_arr, average='weighted',zero_division=0) * 100, 2)\n",
    "    return f1_acc, avg_prec, avg_recall, jc_score_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loop over experiments to create overarching result csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: extrasensory_0E6184E1-90C0-48EE-B25A-F1ECB7B9714E_1days_5_1_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_inc//extrasensory_0E6184E1-90C0-48EE-B25A-F1ECB7B9714E_1days_5_1_TAE/results/results_summary_20220914_162525.json\n",
      "id:0E6184E1-90C0-48EE-B25A-F1ECB7B9714E:(1759, 5)\n",
      "id:0E6184E1-90C0-48EE-B25A-F1ECB7B9714E:(1494, 5)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on 0E6184E1-90C0-48EE-B25A-F1ECB7B9714E\n",
      "Processed for id 0E6184E1-90C0-48EE-B25A-F1ECB7B9714E\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tj/q4_hs7215pl0xywz58dv85l00000gp/T/ipykernel_1390/1613021110.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  jc_samples = gt_eq_pred/gt_or_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto       1.16  82.04   0.58   0.67\n",
      "temporal  41.64  38.34  45.70  40.87\n",
      "combined  41.64  38.34  45.70  40.87\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0       Amusement     80.18      0.31         83.12        100.00   \n",
      "1        ComingIn      0.00      0.00          0.00          0.00   \n",
      "2       Commuting      0.00      0.00          0.00          0.00   \n",
      "3        GoingOut      0.00      0.00          0.00          0.00   \n",
      "4      HavingMeal     57.14      0.31         26.13         17.82   \n",
      "5       HouseWork     71.43      0.59          0.00          0.00   \n",
      "6      InAMeeting      0.00      0.00          0.00          0.00   \n",
      "7      Inactivity      0.00      0.00          0.00          0.00   \n",
      "8      OfficeWork      0.00      0.00          0.00          0.00   \n",
      "9   PreparingMeal    100.00      0.14          0.00          0.00   \n",
      "10       Relaxing     88.89      0.24          0.00          0.00   \n",
      "11       Sleeping     98.60      1.63          0.00          0.00   \n",
      "12  UsingBathroom    100.00      0.11          0.00          0.00   \n",
      "\n",
      "    ppv_combined  tpr_combined  \n",
      "0          83.12        100.00  \n",
      "1           0.00          0.00  \n",
      "2           0.00          0.00  \n",
      "3           0.00          0.00  \n",
      "4          26.13         17.82  \n",
      "5           0.00          0.00  \n",
      "6           0.00          0.00  \n",
      "7           0.00          0.00  \n",
      "8           0.00          0.00  \n",
      "9           0.00          0.00  \n",
      "10          0.00          0.00  \n",
      "11          0.00          0.00  \n",
      "12          0.00          0.00  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment extrasensory_0E6184E1-90C0-48EE-B25A-F1ECB7B9714E_1days_5_1_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "experiment_dirs = glob.glob(f'{overall_cache_dir}/extra*1day*')\n",
    "\n",
    "df_metrics =None\n",
    "for experiment_dir in experiment_dirs:\n",
    "    experiment = experiment_dir.split(\"/\")[-1]\n",
    "    experiment_out_dir = f'{out_result_dir}/{experiment}'\n",
    "    if not os.path.exists(experiment_out_dir):\n",
    "        os.makedirs(experiment_out_dir)\n",
    "\n",
    "    printm(f\"## --------------------------- Started Experiment: {experiment} ----------------------------\")\n",
    "    # Compile results into ts dict\n",
    "    printm(\"### fetch results for experiment\")\n",
    "    if True:\n",
    "        result_file = sorted(glob.glob(f\"{overall_cache_dir}/{experiment}/results/{result_summary_prefix}*.json\"))[-1]\n",
    "        ts_file = sorted(glob.glob(f\"{overall_cache_dir}/{experiment}/results/{ts_prediction_file_prefix}*.pb\"))[-1]\n",
    "        print(result_file)\n",
    "        exp_results = json.load(open(result_file, 'r'))\n",
    "        ts_results = pickle.load(open(ts_file, 'rb'))\n",
    "        cluster_centers = exp_results['direct_labels']\n",
    "        dataset = exp_results['run_config']['dataset']\n",
    "\n",
    "    # Filter out only test instances from ts_results\n",
    "    for id in ts_results.keys():\n",
    "        print(f\"id:{id}:{ts_results[id].shape}\")\n",
    "        ts_results[id] = ts_results[id][ts_results[id].isTrain==False]\n",
    "        print(f\"id:{id}:{ts_results[id].shape}\")\n",
    "\n",
    "    printm(\"### get cluster labels and best representation accuracy\")\n",
    "    if True:\n",
    "        direct_cluster_centers = exp_results['direct_labels']\n",
    "        direct_cluster_labels = get_cluster_labels(direct_cluster_centers, dataset, label_context_v1)\n",
    "        decoded_cluster_centers = exp_results['decoded_labels']\n",
    "        decoded_cluster_labels = get_cluster_labels(decoded_cluster_centers, dataset, label_context_v1)\n",
    "        cluster_labels = []\n",
    "        for idx in range(len(decoded_cluster_labels)):\n",
    "            if len(decoded_cluster_labels[idx]) > 0:\n",
    "                cluster_labels.append(decoded_cluster_labels[idx])\n",
    "            else:\n",
    "                cluster_labels.append(direct_cluster_labels[idx])\n",
    "        df_cluster_merge = pd.DataFrame(np.array([[f\"{idx}:\"+','.join(cr) for idx,cr in enumerate(direct_cluster_labels)],\n",
    "                           [f\"{idx}:\"+','.join(cr) for idx,cr in enumerate(decoded_cluster_labels)],\n",
    "                           [f\"{idx}:\"+','.join(cr) for idx,cr in enumerate(cluster_labels)]]).T,columns=['direct','decoded','combination_1'])\n",
    "        df_cluster_merge.to_csv(f\"{experiment_out_dir}/cluster_merge.csv\")\n",
    "        representation_acc = exp_results['repr_training_metrics'][-1]\n",
    "        json.dump(representation_acc, open(f\"{experiment_out_dir}/representation_accuracy.json\",\"w\"))\n",
    "\n",
    "    printm(\"### compile GT, Onto and Temporal results together\")\n",
    "    compiled_results_ts_dict  = compile_ts_results_v2(ts_results, df_onto_pred,df_gt, cluster_labels)\n",
    "\n",
    "    # get all available context from onto, gt and temporal\n",
    "    printm(\"### get all available contexts\")\n",
    "    if True:\n",
    "        all_context_list = []\n",
    "        for id in compiled_results_ts_dict.keys():\n",
    "            df_ts_id = compiled_results_ts_dict[id]\n",
    "            all_context_list += np.unique(df_ts_id['gt_context'].values).tolist()\n",
    "            all_context_list += np.unique(df_ts_id['pred_context'].values).tolist()\n",
    "            all_context_list += np.unique(df_ts_id['onto_context'].values).tolist()\n",
    "        all_context_list = np.unique(all_context_list).tolist()\n",
    "        all_context_list = [xr.split(\",\") for xr in all_context_list]\n",
    "        all_context_list = sorted(np.unique(np.concatenate(all_context_list)).tolist())\n",
    "        if '' in all_context_list:\n",
    "            del all_context_list[all_context_list.index('')]\n",
    "        if 'Unknown' in all_context_list:\n",
    "            del all_context_list[all_context_list.index('Unknown')]\n",
    "        json.dump(all_context_list, open(f\"{experiment_out_dir}/all_contexts.json\",\"w\"))\n",
    "\n",
    "    # Get metrics\n",
    "    printm(\"### get timestamp level metrics\")\n",
    "    if True:\n",
    "        metric_columns = ['gt_vec','onto_pred_vec','tp_pred_vec','combined_pred_vec']\n",
    "        for id_key in compiled_results_ts_dict.keys():\n",
    "            dft = compiled_results_ts_dict[id_key]\n",
    "            dft['gt_vec'] = dft.apply(lambda row: get_ctx_vec(row['gt_context'], all_context_list),axis=1)\n",
    "            dft['onto_pred_vec'] = dft.apply(lambda row: get_ctx_vec(row['onto_context'], all_context_list),axis=1)\n",
    "            dft['tp_pred_vec'] = dft.apply(lambda row: get_ctx_vec(row['pred_context'], all_context_list),axis=1)\n",
    "            dft['combined_pred_vec'] = dft.apply(lambda row: get_ctx_vec(row['combined_context'], all_context_list),axis=1)\n",
    "\n",
    "        ts_metrics = np.vstack([compiled_results_ts_dict[id][metric_columns].values for id in compiled_results_ts_dict.keys()])\n",
    "        df_ts_metrics = pd.DataFrame(ts_metrics,columns=metric_columns)\n",
    "        pickle.dump(compiled_results_ts_dict,open(f\"{experiment_out_dir}/compiled_results.pb\",\"wb\"))\n",
    "\n",
    "    # Get overall accuracy metrics for timestamps\n",
    "    printm(\"### get overall accuracy metrics\")\n",
    "    if True:\n",
    "        gt_ts_arr = np.stack(df_ts_metrics['gt_vec'].values)\n",
    "        onto_ts_arr = np.stack(df_ts_metrics['onto_pred_vec'].values)\n",
    "        tp_ts_arr = np.stack(df_ts_metrics['tp_pred_vec'].values)\n",
    "        combined_ts_arr = np.stack(df_ts_metrics['combined_pred_vec'].values)\n",
    "        onto_ts_metrics = get_overall_metrics(gt_ts_arr, onto_ts_arr)\n",
    "        tp_ts_metrics = get_overall_metrics(gt_ts_arr, tp_ts_arr)\n",
    "        combined_ts_metrics = get_overall_metrics(gt_ts_arr,combined_ts_arr)\n",
    "        df_overall_ts_metrics = pd.DataFrame([onto_ts_metrics,tp_ts_metrics,combined_ts_metrics],columns=['F1','PPV','TPR','JC'],index=['onto','temporal','combined'])\n",
    "        df_overall_ts_metrics.to_csv(f\"{experiment_out_dir}/overall_metrics.csv\")\n",
    "        print(df_overall_ts_metrics)\n",
    "    # context level accuracy\n",
    "    printm(\"### get context level accuracy metrics\")\n",
    "    if True:\n",
    "        df_context_ts_metrics = pd.DataFrame(all_context_list, columns=['context'])\n",
    "        df_context_ts_metrics['ppv_onto'] = precision_score(gt_ts_arr, onto_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics['tpr_onto'] = recall_score(gt_ts_arr, onto_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics['ppv_temporal'] = precision_score(gt_ts_arr, tp_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics['tpr_temporal'] = recall_score(gt_ts_arr, tp_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics['ppv_combined'] = precision_score(gt_ts_arr, combined_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics['tpr_combined'] = recall_score(gt_ts_arr, combined_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics.to_csv(f\"{experiment_out_dir}/context_metrics.csv\")\n",
    "        print(df_context_ts_metrics)\n",
    "\n",
    "    printm(f\"## Finished Experiment {experiment}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['run_config', 'repr_training_metrics', 'data_embeddings', 'cluster_representations', 'instance_predictions', 'context_representations', 'context_positional_counts', 'direct_labels', 'onto_labels', 'decoded_representations', 'decoded_labels'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    4660\n",
       "True      639\n",
       "Name: isTrain, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_results['csh101'].isTrain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
